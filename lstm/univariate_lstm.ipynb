{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install PyQt5\n",
    "import PyQt5\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../complete_merged.csv\",index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consecutive date checking function (Some districts had partial data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing datetime consecutiveness\n",
    "import datetime as dt\n",
    "\n",
    "def checkConsecutive(date_strs):\n",
    "    dates = [dt.datetime.strptime(d, \"%Y-%m-%d\") for d in date_strs]\n",
    "\n",
    "    date_ints = set([d.toordinal() for d in dates])\n",
    "    if len(date_ints) == 1:\n",
    "        return True\n",
    "    elif max(date_ints) - min(date_ints) == len(date_ints) - 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# date_strs = ['02-29-2012', '02-28-2012', '03-01-2012']\n",
    "date_strs = ['1999-12-31','2000-01-01']\n",
    "checkConsecutive(date_strs)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Sequence(Standard function for splitting data for univariate lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def split_sequence(date_sequence,temp_sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(temp_sequence)):\n",
    "    # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    " # check if we are beyond the sequence\n",
    "        if end_ix > len(temp_sequence)-1:\n",
    "            break\n",
    " # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = temp_sequence[i:end_ix], temp_sequence[end_ix]\n",
    "        date_seq = date_sequence[i:end_ix]\n",
    "        # print(checkConsecutive(seq_x))\n",
    "        if(checkConsecutive(date_seq)):\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Check\n",
    "X,y = split_sequence(['2021-01-09','2021-01-11','2021-01-12','2021-01-13','2021-01-14'],[10, 20, 30, 40, 50],3)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertUnivariateData(date_data,temp_data,n_steps,n_features):\n",
    "    X, y = split_sequence(date_data,temp_data, n_steps)\n",
    "# summarize the data\n",
    "    X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "    return (X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different optimizers and loss functions need to be tested yet\n",
    "n_steps = 10\n",
    "n_features = 1\n",
    "epochs =20\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate model(Mean Square Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalLSTM(model,X,y,n_steps,n_features):\n",
    "    y_predict = list()\n",
    "    for i in range(X.shape[0]):\n",
    "        x_input = X[i]\n",
    "        x_input = x_input.reshape((1, n_steps, n_features))\n",
    "        predicted_value = model.predict(x_input, verbose=0)[0][0]\n",
    "        print(len(y_predict),\"of\",X.shape[0])\n",
    "        y_predict.append(predicted_value)\n",
    "    \n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    return {'mse':mse(y_predict,y).numpy(),'y_predict':y_predict}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic check for Adilabad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Adilabad = data[data['district'] == \"Adilabad\"].sort_values(axis = 0,by = \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Adilabad_temp = data_Adilabad['temp_max'].to_list()\n",
    "data_Adilabad_date = data_Adilabad['date'].to_list()\n",
    "# print(data_Adilabad_date)\n",
    "X,y = convertUnivariateData(data_Adilabad_date,data_Adilabad_temp,n_steps,n_features)\n",
    "model.fit(X, y, epochs=200, verbose=4)\n",
    "mse = evalLSTM(model,X,y,10,1)\n",
    "mse\n",
    "#3.36 for 200 epochs\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "plt.plot(y)\n",
    "plt.plot(mse['y_predict'])\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various window sizes were used on Adilabad for optimization.Results were as follows:\n",
    "\n",
    "[10-3.289,\n",
    " 20-55142.400,\n",
    " 30-6766769.447,\n",
    " 40-216242835.855,\n",
    " 50-14841958357.522,\n",
    " 60-793333303283.484]\n",
    "\n",
    "\n",
    "[7-116.768,\n",
    " 8-28.928,\n",
    " 9-5.358,\n",
    " 10-3.289,\n",
    " 11-5.317]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluding that 10 is an optimal window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(district,column):\n",
    "    return data[data['district'] == district].sort_values(axis = 0,by = \"date\")[column].to_list()\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on complete data of all districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for district in data['district'].unique():\n",
    "    print(str(i) + \"out of \"+str(len(data['district'].unique())))\n",
    "    \n",
    "    data_unique_district_temp = get_data(district,'temp_max')\n",
    "    data_unique_district_date = get_data(district,'date')\n",
    "    \n",
    "    print(district,str(len(data_unique_district_temp)))\n",
    "    X,y = convertUnivariateData(data_unique_district_date, data_unique_district_temp,n_steps,n_features)\n",
    "    model.fit(X, y, epochs=epochs, verbose=0)\n",
    "    i = i+1\n",
    "    \n",
    "    # print(data_unique_district_temp)\n",
    "\n",
    "#mse = 3.042 for epochs = 20 for Hanumakonda\n",
    "#mse = 4.34 for Adilabad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'mse': 3.042855618505585 when trained on all data and tested against random 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unique_district_temp = get_data('Adilabad','temp_max')\n",
    "data_unique_district_date = get_data('Adilabad','date')\n",
    "    \n",
    "  \n",
    "X,y = convertUnivariateData(data_unique_district_date, data_unique_district_temp,n_steps,n_features)\n",
    "mse = evalLSTM(model,X,y,10,1)\n",
    "plt.plot(y)\n",
    "plt.plot(mse['y_predict'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "909f0b76f81b73c0ef4c751cc35ea89d4758d30c8c87996ed8f07628885546c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
